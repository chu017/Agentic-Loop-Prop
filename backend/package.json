{
  "name": "propai-backend",
  "version": "1.0.0",
  "description": "Backend server for PropAI agent with LLM integration",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "dependencies": {
    "axios": "^1.4.0",
    "cors": "^2.8.5",
    "dotenv": "^16.3.1",
    "express": "^4.18.2",
    "express-rate-limit": "^6.11.2",
    "helmet": "^7.0.0",
    "morgan": "^1.10.0",
    "openai": "^4.0.0",
    "rate-limiter-flexible": "^2.4.2",
    "uuid": "^9.0.0"
  },
  "devDependencies": {
    "nodemon": "^3.0.1"
  },
  "keywords": [
    "ai",
    "agent",
    "chatbot",
    "express",
    "openrouter",
    "llm"
  ],
  "author": "",
  "license": "MIT"
}
